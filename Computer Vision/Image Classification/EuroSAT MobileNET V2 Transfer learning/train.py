# -*- coding: utf-8 -*-
"""EUROSAT TRANSFER LEARNING.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DtQhEunqYwe2LGLRVVHEEiNB8aX14Idm
"""

from __future__ import print_function, division
from builtins import range, input

import tensorflow as tf

from keras.layers import Input, Lambda, Dense, Flatten
from keras.models import Model
from keras.applications.mobilenet_v2 import MobileNetV2
from keras.applications.mobilenet_v2 import preprocess_input
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator

from sklearn.metrics import confusion_matrix
import numpy as np
import matplotlib.pyplot as plt

import glob
import os
import shutil

_LABELS = [
    'AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial',
    'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake'
]

'''
Download the file from below url, downloded and extracted will stored in zip_file
'''
_URL = "http://madm.dfki.de/files/sentinel/EuroSAT.zip"

zip_file = tf.keras.utils.get_file(origin=_URL,
                                   fname="EuroSat.tgz",
                                   extract=True)

base_dir = os.path.join(os.path.dirname(zip_file), '2750')
print(base_dir)


def split_dataset(labels, base_dir, train_test_val_split = False, train_split = 0.8):
  for cl in labels:
    img_path = os.path.join(base_dir, cl)
    images = glob.glob(img_path + '/*.jpg')
    print("{}: {} Images".format(cl, len(images)))
    num_train = int(round(len(images)*train_split))
    if train_test_val_split:
      num_val = int(num_train + (len(images) - num_train)/2)
      train, val, test = images[:num_train], images[num_train:num_val], images[num_val:]
    else:
      train, val = images[:num_train], images[num_train:]

    for t in train:
      if not os.path.exists(os.path.join(base_dir, 'train', cl)):
        os.makedirs(os.path.join(base_dir, 'train', cl))
      shutil.move(t, os.path.join(base_dir, 'train', cl))

    for v in val:
      if not os.path.exists(os.path.join(base_dir, 'val', cl)):
        os.makedirs(os.path.join(base_dir, 'val', cl))
      shutil.move(v, os.path.join(base_dir, 'val', cl))
      
    if test:
      for v in test:
        if not os.path.exists(os.path.join(base_dir, 'test', cl)):
          os.makedirs(os.path.join(base_dir, 'test', cl))
        shutil.move(v, os.path.join(base_dir, 'test', cl))

  train_dir = os.path.join(base_dir, 'train')
  val_dir = os.path.join(base_dir, 'val')

  if test:
    test_dir = os.path.join(base_dir, "test")
    return train_dir, val_dir, test_dir
  
  return train_dir, val_dir

'''
If test split is not required then make train_test_val_split = False
'''
train_dir, val_dir, test_dir = split_dataset(_LABELS, base_dir, train_test_val_split = True)


'''
Please fell free to chage IMAGE_SIZE
'''
IMAGE_SIZE = [128, 128]

epochs = 10
batch_size = 64

'''
Collects the class folders paths not images paths, this is used later for annotations.
'''
folders = glob.glob(train_dir + "/*")
print("Paths for classess: {}".format(folders))
print("Total no.of classess: {}".format(len(folders)))

'''
Collecting images paths from three splits, if test split is not there please
Comment out test_img_files line.
This contains a list of image paths.
'''
train_img_files = glob.glob(train_dir + "/*/*.jpg")
val_img_files = glob.glob(val_dir + "/*/*.jpg")
test_img_files = glob.glob(test_dir+'/*/*.jpg')

print("Total no.of train images: {}".format(len(train_img_files)))
print("Total no.of val images: {}".format(len(val_img_files)))
print("Total no.of test images: {}".format(len(test_img_files)))

'''
np.random.choice selects a random image path from train_img_files
'''
plt.imshow(image.load_img(np.random.choice(train_img_files)))
plt.show()

'''
Using imagenet weights for mobilenet
'''
mobilenet = MobileNetV2(input_shape = IMAGE_SIZE + [3], weights = 'imagenet', include_top = False)

for layer in mobilenet.layers:
  layer.trainable = False

x = Flatten()(mobilenet.output)
prediction = Dense(len(folders), activation = 'softmax')(x)

model = Model(inputs = mobilenet.input, outputs = prediction)

model.summary()

'''
To plot model graphviz is required, if not required please comment out this line.
'''
tf.keras.utils.plot_model(model)

history = model.compile(
    loss = "categorical_crossentropy",
    optimizer = "adam",
    metrics = ["accuracy"]
)

gen = ImageDataGenerator(
    rotation_range = 20,
    width_shift_range = 0.1,
    height_shift_range = 0.1,
    shear_range = 0.1,
    zoom_range = 0.2,
    horizontal_flip = True,
    vertical_flip = True,
    preprocessing_function = preprocess_input  #preprocess_input is different for each model, import it from keras.application.model_name
)

test_images = gen.flow_from_directory(val_dir, target_size = IMAGE_SIZE)
print(test_images.class_indices)
labels = [None] * len(test_images.class_indices)

for k,v in test_images.class_indices.items():
  labels[v] = k

for x, y in test_images:
  print("min:", x[0].min(), "max:", x[0].max())
  plt.title(labels[np.argmax(y[0])])
  plt.imshow(x[0])
  plt.show()
  break

train_images = gen.flow_from_directory(
    train_dir,
    target_size = IMAGE_SIZE,
    shuffle = True,
    batch_size = batch_size,
)

val_images = gen.flow_from_directory(
    val_dir,
    target_size = IMAGE_SIZE,
    shuffle = True,
    batch_size = batch_size,
)

history = model.fit_generator(
    train_images,
    validation_data = val_images,
    epochs = epochs,
    steps_per_epoch = len(train_img_files)//batch_size,
    validation_steps = len(val_img_files)//batch_size
)

model.save("models/mobilenet_v2_eurosat_128.hdf5")



