# -*- coding: utf-8 -*-
"""EuroSat2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DVhyV_AYaYRMyZ8ZZlE9uPVvfAD13s3q
"""

#IMPORTS 
import os
import numpy as np
import glob
import shutil
import matplotlib.pyplot as plt
plt.rcParams['figure.figsize'] = [20, 10]

import tensorflow as tf

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
print(tf.__version__)

#CLASS LABELS IN DATASET
#DATASET CONSITS OF 27000 IMAGES
_LABELS = [
    'AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial',
    'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake'
]

#API USED TO DOWNLOAD
_URL = "http://madm.dfki.de/files/sentinel/EuroSAT.zip"

zip_file = tf.keras.utils.get_file(origin=_URL,
                                   fname="EuroSat.tgz",
                                   extract=True)

#SAVE THE PATH WHERE DOWNLOADED FILE EXISTS
base_dir = os.path.join(os.path.dirname(zip_file), '2750')

#DIVIDING THE ENTIRE DATASET INTO TRAIN AND VAL DIRECTORIES
for cl in _LABELS:
  img_path = os.path.join(base_dir, cl)
  images = glob.glob(img_path + '/*.jpg')
  print("{}: {} Images".format(cl, len(images)))
  num_train = int(round(len(images)*0.8)) #FOR TRAIN WE ARE CONSIDERING 80% OF DATA, SO WE MULTIPLIED len(images) WITH 0.8
  train, val = images[:num_train], images[num_train:]

  for t in train:
    if not os.path.exists(os.path.join(base_dir, 'train', cl)):
      os.makedirs(os.path.join(base_dir, 'train', cl))
    shutil.move(t, os.path.join(base_dir, 'train', cl))

  for v in val:
    if not os.path.exists(os.path.join(base_dir, 'val', cl)):
      os.makedirs(os.path.join(base_dir, 'val', cl))
    shutil.move(v, os.path.join(base_dir, 'val', cl))

#SAVING TRAIN AND VAL DIRECTORIES PATH
train_dir = os.path.join(base_dir, 'train')
val_dir = os.path.join(base_dir, 'val')

batch_size = 100
IMG_SHAPE = 150

#IMAGE GENERATORS, DATA READING AND AUGMENTATION WILL DONE HERE
image_gen_train = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=45,
                    width_shift_range=.15,
                    height_shift_range=.15,
                    horizontal_flip=True,
                    zoom_range=0.5
                    )


train_data_gen = image_gen_train.flow_from_directory(
                                                batch_size=batch_size,
                                                directory=train_dir,
                                                shuffle=True,
                                                target_size=(IMG_SHAPE,IMG_SHAPE),
                                                class_mode='sparse'
                                                )

image_gen_val = ImageDataGenerator(rescale=1./255)

#FOR VAL DATA DATA AUGMENTATION SHOLDN'T BE DONE
val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,
                                                 directory=val_dir,
                                                 target_size=(IMG_SHAPE, IMG_SHAPE),
                                                 class_mode='sparse')

# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.
def plotImages(images_arr):
    fig, axes = plt.subplots(1, 5, figsize=(20,20))
    axes = axes.flatten()
    for img, ax in zip( images_arr, axes):
        ax.imshow(img)
    plt.tight_layout()
    plt.show()


augmented_images = [train_data_gen[0][0][0] for i in range(5)]
plotImages(augmented_images)

#SEQUENTIAL MODEL
model = Sequential()

model.add(Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_SHAPE,IMG_SHAPE, 3)))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(32, 3, padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, 3, padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())
model.add(Dropout(0.2))
model.add(Dense(512, activation='relu'))

model.add(Dropout(0.2))
model.add(Dense(10, activation='softmax'))

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

epochs = 100

#FITING, HERE WE USED GENERATORS SO WE USED fit_generator, You can also use model.fit() but you will get some warnings.

history = model.fit_generator(
    train_data_gen,
    steps_per_epoch=int(np.ceil(train_data_gen.n / float(batch_size))),
    epochs=epochs,
    validation_data=val_data_gen,
    validation_steps=int(np.ceil(val_data_gen.n / float(batch_size)))
)

#Save the model at models/EuroSat.h5
model.save('models/EuroSat.h5')
