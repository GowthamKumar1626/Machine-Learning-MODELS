# -*- coding: utf-8 -*-
"""EuroSatVGG TransferLearning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DfG9ARB44DYQcm5DF-KgbbbZdvXFI1V3
"""

from __future__ import print_function, division
from builtins import range, input

import tensorflow as tf

from keras.layers import Input, Lambda, Dense, Flatten
from keras.models import Model
from keras.applications.vgg16 import VGG16
from keras.applications.vgg16 import preprocess_input, decode_predictions
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator

from sklearn.metrics import confusion_matrix
import numpy as np
import matplotlib.pyplot as plt

import glob
import os
import shutil

_URL = "http://madm.dfki.de/files/sentinel/EuroSAT.zip"

zip_file = tf.keras.utils.get_file(origin=_URL,
                                   fname="EuroSat.tgz",
                                   extract=True)

base_dir = os.path.join(os.path.dirname(zip_file), '2750')

_LABELS = [
    'AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial',
    'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake'
]

'''
Dividing entire dataset into train and val.
If you want to divide inti train, val and test in split_dataset function call
make train_test_split = True.
Specify only train split ratio, default is 0.8

This function return directory paths of train, val, test(if mentioned) respectively.
'''

def split_dataset(labels, base_dir, train_test_val_split = False, train_split = 0.8):
  for cl in labels:
    img_path = os.path.join(base_dir, cl)
    images = glob.glob(img_path + '/*.jpg')
    print("{}: {} Images".format(cl, len(images)))
    num_train = int(round(len(images)*train_split))
    if train_test_val_split:
      num_val = int(num_train + (len(images) - num_train)/2)
      train, val, test = images[:num_train], images[num_train:num_val], images[num_val:]
    else:
      train, val = images[:num_train], images[num_train:]

    for t in train:
      if not os.path.exists(os.path.join(base_dir, 'train', cl)):
        os.makedirs(os.path.join(base_dir, 'train', cl))
      shutil.move(t, os.path.join(base_dir, 'train', cl))

    for v in val:
      if not os.path.exists(os.path.join(base_dir, 'val', cl)):
        os.makedirs(os.path.join(base_dir, 'val', cl))
      shutil.move(v, os.path.join(base_dir, 'val', cl))
      
    if test:
      for v in test:
        if not os.path.exists(os.path.join(base_dir, 'test', cl)):
          os.makedirs(os.path.join(base_dir, 'test', cl))
        shutil.move(v, os.path.join(base_dir, 'test', cl))

  train_dir = os.path.join(base_dir, 'train')
  val_dir = os.path.join(base_dir, 'val')

  if test:
    test_dir = os.path.join(base_dir, "test")
    return train_dir, val_dir, test_dir
  
  return train_dir, val_dir

'''
Split dataset function call
returns train, val, test dir paths (test dir if only mentioned) respectively
'''  
train_dir, val_dir = split_dataset(_LABELS, base_dir)


IMAGE_SIZE = [100, 100]

epochs = 10
batch_size = 32

''' This step is useful if your images are divided according to directories'''
folders = glob.glob(train_dir + "/*")
print("Paths for classess: {}".format(folders))
print("Total no.of classess: {}".format(len(folders)))

'''
glob collects the paths of all images with extension .jpg
If your dataset consists of .png files please remove alpha channel after reading
like image = image[:,:,:3] this will takes up to 3 layers removes alpha channel
If your dataset consists of both jpg and jpeg use "/*/*.jp*g" in glob
'''
train_img_files = glob.glob(train_dir + "/*/*.jpg")
val_img_files = glob.glob(val_dir + "/*/*jpg")

print("Total no.of train images: {}".format(len(train_img_files)))
print("Total no.of val images: {}".format(len(val_img_files)))

#Plots a random image from list of train_img_files
plt.imshow(image.load_img(np.random.choice(train_img_files)))
plt.show()

'''
Using imagenet weights, you can use other weights also
include_top = False where removing last dense layer with sofmax activation.
'''
vgg = VGG16(input_shape = IMAGE_SIZE + [3], weights = 'imagenet', include_top = False)

#Freezing the layers
for layer in vgg.layers:
  layer.trainable = False

x = Flatten()(vgg.output)
prediction = Dense(len(folders), activation = "softmax")(x)

model = Model(inputs = vgg.input, outputs = prediction)

model.summary()

'''
If you are using one-hot encoding for labels use categorical cross entropy
else use space categorical loss entropy
Loss function for both is same.'''

history = model.compile(
    loss = "categorical_crossentropy",
    optimizer = "adam",
    metrics = ["accuracy"]
)

gen = ImageDataGenerator(
    rotation_range = 20,
    width_shift_range = 0.1,
    height_shift_range = 0.1,
    shear_range = 0.1,
    zoom_range = 0.2,
    horizontal_flip = True,
    vertical_flip = True,
    preprocessing_function = preprocess_input
)

test_images = gen.flow_from_directory(val_dir, target_size = IMAGE_SIZE)
print(test_images.class_indices)
labels = [None] * len(test_images.class_indices)

for k,v in test_images.class_indices.items():
  labels[v] = k

'''
Here you will get weired images.
It is because in ImageDataGenerator we used preprocess_inout.
This preprocess input is unique for every net like resnet, mobilenet etc.
VGG16 usees BGR format.
If you get weired images then you loaded data correctly else wrong.
'''
for x, y in test_images:
  print("min:", x[0].min(), "max:", x[0].max())
  plt.title(labels[np.argmax(y[0])])
  plt.imshow(x[0])
  plt.show()
  break

train_images = gen.flow_from_directory(
    train_dir,
    target_size = IMAGE_SIZE,
    shuffle = True,
    batch_size = batch_size,
)

val_images = gen.flow_from_directory(
    val_dir,
    target_size = IMAGE_SIZE,
    shuffle = True,
    batch_size = batch_size,
)

#Plot model architecture.
tf.keras.utils.plot_model(model)

'''
Here we use generators to read the data.
So we used fit_generator.
'''
history = model.fit_generator(
    train_images,
    validation_data = val_images,
    epochs = epochs,
    steps_per_epoch = len(train_img_files)//batch_size,
    validation_steps = len(val_img_files)//batch_size
)

#Model Performance
plt.plot(history.history["loss"])
plt.plot(history.history["val_loss"])
plt.ylim(top=5)
plt.show()

plt.plot(history.history["accuracy"])
plt.plot(history.history["val_accuracy"])
plt.show()

#Saving model into model directory
model.save("model/EuroSat VGG_16.hdf5")

#For predictions use CODE from test.py



