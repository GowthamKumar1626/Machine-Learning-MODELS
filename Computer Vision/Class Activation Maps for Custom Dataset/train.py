# -*- coding: utf-8 -*-
"""EuroSAT ClassActivationMap with ResNET50.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Czoh7S2d76rIf5NKtoH72k12ssPLC9Ip
"""

from __future__ import print_function, division
from builtins import range, input

import tensorflow as tf

from keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D
from keras.models import Model
from keras.applications.resnet50 import ResNet50
from keras.applications.resnet50 import preprocess_input, decode_predictions
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator

from sklearn.metrics import confusion_matrix
import numpy as np
import matplotlib.pyplot as plt
import scipy as sp

import glob
import os
import shutil
import pickle

from google.colab import drive
drive.mount('/content/drive')

'''
Download dataset from API
'''
_URL = "http://madm.dfki.de/files/sentinel/EuroSAT.zip"

zip_file = tf.keras.utils.get_file(origin=_URL,
                                   fname="EuroSat.tgz",
                                   extract=True)

'''
Copy the file location to base_dir
'''
base_dir = os.path.join(os.path.dirname(zip_file), '2750')

'''
Store the labels
'''
_LABELS = [
    'AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial',
    'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake'
]

'''
train, val, test split function
'''
def split_dataset(labels, base_dir, train_test_val_split = False, train_split = 0.8):
  for cl in labels:
    img_path = os.path.join(base_dir, cl)
    images = glob.glob(img_path + '/*.jpg')
    print("{}: {} Images".format(cl, len(images)))
    num_train = int(round(len(images)*train_split))
    if train_test_val_split:
      num_val = int(num_train + (len(images) - num_train)/2)
      train, val, test = images[:num_train], images[num_train:num_val], images[num_val:]
    else:
      train, val = images[:num_train], images[num_train:]

    for t in train:
      if not os.path.exists(os.path.join(base_dir, 'train', cl)):
        os.makedirs(os.path.join(base_dir, 'train', cl))
      shutil.move(t, os.path.join(base_dir, 'train', cl))

    for v in val:
      if not os.path.exists(os.path.join(base_dir, 'val', cl)):
        os.makedirs(os.path.join(base_dir, 'val', cl))
      shutil.move(v, os.path.join(base_dir, 'val', cl))
      
    if test:
      for v in test:
        if not os.path.exists(os.path.join(base_dir, 'test', cl)):
          os.makedirs(os.path.join(base_dir, 'test', cl))
        shutil.move(v, os.path.join(base_dir, 'test', cl))

  train_dir = os.path.join(base_dir, 'train')
  val_dir = os.path.join(base_dir, 'val')

  if test:
    test_dir = os.path.join(base_dir, "test")
    return train_dir, val_dir, test_dir
  
  return train_dir, val_dir

'''
Split dataset function call
returns train, val, test dir paths (test dir if only mentioned) respectively
'''  
train_dir, val_dir, test_dir = split_dataset(_LABELS, base_dir, train_test_val_split = True)

'''
Input image size
'''
IMAGE_SIZE = [224, 224]

epochs = 5
batch_size = 64

'''
Collect paths of each category dirs
'''
folders = glob.glob(train_dir + "/*")
print("Paths for classess: {}".format(folders))
print("Total no.of classess: {}".format(len(folders)))

'''
Collecting image paths
'''
train_img_files = glob.glob(train_dir + "/*/*.jpg")
val_img_files = glob.glob(val_dir + "/*/*jpg")
test_img_files = glob.glob(test_dir + "/*/*.jpg")

print("Total no.of train images: {}".format(len(train_img_files)))
print("Total no.of val images: {}".format(len(val_img_files)))
print("Total no.of test images: {}".format(len(test_img_files)))

'''
Save the image paths of test set using pickle to use in classactivationmap.py file
'''

pickle_out = open("test.pickle", "wb")
pickle.dump(test_img_files, pickle_out)
pickle_out.close()

'''
Plot a random image using np.random.choice()
'''
plt.imshow(image.load_img(np.random.choice(train_img_files)))
plt.show()

'''
Loading ResNet50 model with imagenet weights, include_top = False
'''
resnet = ResNet50(input_shape = IMAGE_SIZE + [3], weights = 'imagenet', include_top = False)

for layer in resnet.layers:
  layer.trainable = False

'''
For making class activation maps, we need to use GlobalAveragePooling2D() insted of Flatten()
'''
x = GlobalAveragePooling2D()(resnet.output)
prediction = Dense(len(folders), activation = "softmax", name="predictions")(x)

model = Model(inputs = resnet.input, outputs = prediction)

model.summary()

history = model.compile(
    loss = "categorical_crossentropy",
    optimizer = "adam",
    metrics = ["accuracy"]
)

gen = ImageDataGenerator(
    rotation_range = 20,
    width_shift_range = 0.1,
    height_shift_range = 0.1,
    shear_range = 0.1,
    zoom_range = 0.2,
    horizontal_flip = True,
    vertical_flip = True,
    preprocessing_function = preprocess_input
)

test_images = gen.flow_from_directory(val_dir, target_size = IMAGE_SIZE)
print(test_images.class_indices)
labels = [None] * len(test_images.class_indices)

for k,v in test_images.class_indices.items():
  labels[v] = k

'''
Here images are displayed after image is passed through preprocess_input function
Result will be weired, So don't worry
'''
for x, y in test_images:
  print("min:", x[0].min(), "max:", x[0].max())
  plt.title(labels[np.argmax(y[0])])
  plt.imshow(x[0])
  plt.show()
  break

'''
Using generators to collect images
'''
train_images = gen.flow_from_directory(
    train_dir,
    target_size = IMAGE_SIZE,
    shuffle = True,
    batch_size = batch_size,
)

val_images = gen.flow_from_directory(
    val_dir,
    target_size = IMAGE_SIZE,
    shuffle = True,
    batch_size = batch_size,
)

type(train_images)

for image, label in train_images:
  print(image[0].shape, label[0])
  print(type(image[0][0][0][0]), type(label[0][0]))
  break

history = model.fit_generator(
    train_images,
    validation_data = val_images,
    epochs = epochs,
    steps_per_epoch = len(train_img_files)//batch_size,
    validation_steps = len(val_img_files)//batch_size
)

plt.plot(history.history["loss"])
plt.plot(history.history["val_loss"])
plt.ylim(top=0.75)
plt.show()

plt.plot(history.history["accuracy"])
plt.plot(history.history["val_accuracy"])
plt.show()


'''
Save the model to Model dir
'''
model.save("Model/ResNet50.hdf5")

'''
Use classactivationmap.py file to create activation maps
'''

